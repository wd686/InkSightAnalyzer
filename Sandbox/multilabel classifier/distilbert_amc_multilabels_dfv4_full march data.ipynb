{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is available. Using NVIDIA GeForce RTX 3070 Ti Laptop GPU.\n",
      "Tensor is on: cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Check if GPU is available\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")  # Use GPU\n",
    "    print(f\"GPU is available. Using {torch.cuda.get_device_name(0)}.\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")   # Use CPU\n",
    "    print(\"GPU is not available. Using CPU.\")\n",
    "\n",
    "# Example: Moving a tensor or model to the device (GPU or CPU)\n",
    "# tensor = torch.tensor([1, 2, 3]).to(device)\n",
    "# model = model.to(device)  # If you have a model\n",
    "\n",
    "# Example tensor to verify it's on the correct device\n",
    "tensor = torch.tensor([1, 2, 3], device=device)\n",
    "print(f\"Tensor is on: {tensor.device}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model is loaded with 5 output classes and using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import DistilBertTokenizerFast, DistilBertForSequenceClassification\n",
    "\n",
    "# Number of labels for multilabel classification (set this based on your task)\n",
    "num_classes = 5  # Change this to the actual number of classes you have\n",
    "\n",
    "# Load tokenizer\n",
    "tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')\n",
    "\n",
    "# Load pre-trained DistilBERT model for multilabel classification\n",
    "model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=num_classes)\n",
    "model.config.problem_type = \"multi_label_classification\"  # Set the problem type\n",
    "\n",
    "# Check if GPU is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Print confirmation\n",
    "print(f'Model is loaded with {num_classes} output classes and using device: {device}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                       Combined Text Month of Response Date  \\\n",
      "0  Reasonable priced with a high capacity of prints.                 Sep-23   \n",
      "1                     Quick delivery, easy to order!                 Dec-23   \n",
      "2  I bought HP ink for my printer and it is the o...                 Jul-23   \n",
      "3  Best price for good ink cartridge. Easy to ins...                 Mar-24   \n",
      "4  always buy brand have had such bad luck with a...                 Aug-23   \n",
      "\n",
      "           Aspect 1  Aspect 2 Aspect 3 Aspect 4              Output Labels  \n",
      "0               NaN       NaN    Price      NaN                    [Price]  \n",
      "1               NaN  Delivery      NaN      NaN                 [Delivery]  \n",
      "2               NaN       NaN      NaN      NaN                         []  \n",
      "3  Customer Service       NaN    Price      NaN  [Customer Service, Price]  \n",
      "4               NaN       NaN      NaN      NaN                         []  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the CSV file\n",
    "file_path = 'combined_dfv4.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Define the list of possible output labels\n",
    "output_labels = ['Delivery', 'Product Quality', 'Price', 'Customer Service']\n",
    "\n",
    "# Function to extract labels from the 'Aspect 1', 'Aspect 2', 'Aspect 3' columns\n",
    "def extract_labels(row):\n",
    "    labels = []\n",
    "    for aspect in ['Aspect 1', 'Aspect 2', 'Aspect 3', 'Aspect 4']:\n",
    "        if row[aspect] in output_labels:\n",
    "            labels.append(row[aspect])\n",
    "    return labels\n",
    "\n",
    "# Create a new column with the list of output labels\n",
    "df['Output Labels'] = df.apply(extract_labels, axis=1)\n",
    "\n",
    "# Display the first few rows to check the result\n",
    "print(df[['Combined Text', 'Month of Response Date','Aspect 1', 'Aspect 2', 'Aspect 3', 'Aspect 4', 'Output Labels']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Survey ID                      int64\n",
      "Product Name                  object\n",
      "Print Customer Region         object\n",
      "LTR                            int64\n",
      "Source Type                   object\n",
      "Survey language               object\n",
      "Review Source                 object\n",
      "Star Rating                  float64\n",
      "Product Family                object\n",
      "Supplies Family               object\n",
      "Printer Family                object\n",
      "Model Name                    object\n",
      "Combined Text                 object\n",
      "Ink Supply Type               object\n",
      "token_count                    int64\n",
      "Month of Response Date        object\n",
      "predicted_level1              object\n",
      "predicted_probabilities       object\n",
      "predicted_aspect              object\n",
      "max_predicted_probability    float64\n",
      "max_predicted_aspect          object\n",
      "0                            float64\n",
      "Aspect 1                      object\n",
      "Aspect 2                      object\n",
      "Aspect 3                      object\n",
      "Aspect 4                      object\n",
      "Output Labels                 object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survey ID</th>\n",
       "      <th>Product Name</th>\n",
       "      <th>Print Customer Region</th>\n",
       "      <th>LTR</th>\n",
       "      <th>Source Type</th>\n",
       "      <th>Survey language</th>\n",
       "      <th>Review Source</th>\n",
       "      <th>Star Rating</th>\n",
       "      <th>Product Family</th>\n",
       "      <th>Supplies Family</th>\n",
       "      <th>...</th>\n",
       "      <th>predicted_probabilities</th>\n",
       "      <th>predicted_aspect</th>\n",
       "      <th>max_predicted_probability</th>\n",
       "      <th>max_predicted_aspect</th>\n",
       "      <th>0</th>\n",
       "      <th>Aspect 1</th>\n",
       "      <th>Aspect 2</th>\n",
       "      <th>Aspect 3</th>\n",
       "      <th>Aspect 4</th>\n",
       "      <th>Output Labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>110020182</td>\n",
       "      <td>HP 63 Black Original Ink Cartridge</td>\n",
       "      <td>US</td>\n",
       "      <td>10</td>\n",
       "      <td>Web Reviews</td>\n",
       "      <td>English</td>\n",
       "      <td>Walmart</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Supplies - Ink</td>\n",
       "      <td>Dolmen Refresh</td>\n",
       "      <td>...</td>\n",
       "      <td>['0.8352197918762199', '0.7786848755893012']</td>\n",
       "      <td>Delivery, 0</td>\n",
       "      <td>0.835220</td>\n",
       "      <td>Delivery</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Delivery</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[Delivery]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>123460320</td>\n",
       "      <td>HP 65XL Black Original Ink Cartridge</td>\n",
       "      <td>US</td>\n",
       "      <td>10</td>\n",
       "      <td>Web Reviews</td>\n",
       "      <td>English</td>\n",
       "      <td>Walmart</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Supplies - Ink</td>\n",
       "      <td>Dolmen Refresh</td>\n",
       "      <td>...</td>\n",
       "      <td>['0.7908739113381595']</td>\n",
       "      <td>Delivery</td>\n",
       "      <td>0.790874</td>\n",
       "      <td>Delivery</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Delivery</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[Delivery]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>133472112</td>\n",
       "      <td>HP 64XL High Yield Tri-color Original Ink Cart...</td>\n",
       "      <td>US</td>\n",
       "      <td>10</td>\n",
       "      <td>Web Reviews</td>\n",
       "      <td>English</td>\n",
       "      <td>Walmart</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Supplies - Ink</td>\n",
       "      <td>Centaur</td>\n",
       "      <td>...</td>\n",
       "      <td>['0.8070593486001005', '0.7121404761904764', '...</td>\n",
       "      <td>Delivery, Customer Service, Price</td>\n",
       "      <td>0.807059</td>\n",
       "      <td>Delivery</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Customer Service</td>\n",
       "      <td>Delivery</td>\n",
       "      <td>Price</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[Customer Service, Delivery, Price]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>134626563</td>\n",
       "      <td>HP 65XL Black Original Ink Cartridge</td>\n",
       "      <td>US</td>\n",
       "      <td>10</td>\n",
       "      <td>Web Reviews</td>\n",
       "      <td>English</td>\n",
       "      <td>Walmart</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Supplies - Ink</td>\n",
       "      <td>Dolmen Refresh</td>\n",
       "      <td>...</td>\n",
       "      <td>['0.7097935292855333', '0.761109698797934']</td>\n",
       "      <td>Customer Service, Product Quality</td>\n",
       "      <td>0.761110</td>\n",
       "      <td>Product Quality</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Customer Service</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Product Quality</td>\n",
       "      <td>[Customer Service, Product Quality]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312</th>\n",
       "      <td>172491173</td>\n",
       "      <td>HP 65XL Black Original Ink Cartridge</td>\n",
       "      <td>US</td>\n",
       "      <td>10</td>\n",
       "      <td>Web Reviews</td>\n",
       "      <td>English</td>\n",
       "      <td>Walmart</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Supplies - Ink</td>\n",
       "      <td>Dolmen Refresh</td>\n",
       "      <td>...</td>\n",
       "      <td>['0.7133459591878705']</td>\n",
       "      <td>Product Quality</td>\n",
       "      <td>0.713346</td>\n",
       "      <td>Product Quality</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Product Quality</td>\n",
       "      <td>[Product Quality]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Survey ID                                       Product Name  \\\n",
       "18   110020182                 HP 63 Black Original Ink Cartridge   \n",
       "108  123460320               HP 65XL Black Original Ink Cartridge   \n",
       "141  133472112  HP 64XL High Yield Tri-color Original Ink Cart...   \n",
       "155  134626563               HP 65XL Black Original Ink Cartridge   \n",
       "312  172491173               HP 65XL Black Original Ink Cartridge   \n",
       "\n",
       "    Print Customer Region  LTR  Source Type Survey language Review Source  \\\n",
       "18                     US   10  Web Reviews         English       Walmart   \n",
       "108                    US   10  Web Reviews         English       Walmart   \n",
       "141                    US   10  Web Reviews         English       Walmart   \n",
       "155                    US   10  Web Reviews         English       Walmart   \n",
       "312                    US   10  Web Reviews         English       Walmart   \n",
       "\n",
       "     Star Rating  Product Family Supplies Family  ...  \\\n",
       "18           5.0  Supplies - Ink  Dolmen Refresh  ...   \n",
       "108          5.0  Supplies - Ink  Dolmen Refresh  ...   \n",
       "141          5.0  Supplies - Ink         Centaur  ...   \n",
       "155          5.0  Supplies - Ink  Dolmen Refresh  ...   \n",
       "312          5.0  Supplies - Ink  Dolmen Refresh  ...   \n",
       "\n",
       "                               predicted_probabilities  \\\n",
       "18        ['0.8352197918762199', '0.7786848755893012']   \n",
       "108                             ['0.7908739113381595']   \n",
       "141  ['0.8070593486001005', '0.7121404761904764', '...   \n",
       "155        ['0.7097935292855333', '0.761109698797934']   \n",
       "312                             ['0.7133459591878705']   \n",
       "\n",
       "                      predicted_aspect max_predicted_probability  \\\n",
       "18                         Delivery, 0                  0.835220   \n",
       "108                           Delivery                  0.790874   \n",
       "141  Delivery, Customer Service, Price                  0.807059   \n",
       "155  Customer Service, Product Quality                  0.761110   \n",
       "312                    Product Quality                  0.713346   \n",
       "\n",
       "    max_predicted_aspect    0          Aspect 1  Aspect 2 Aspect 3  \\\n",
       "18              Delivery  0.0               NaN  Delivery      NaN   \n",
       "108             Delivery  NaN               NaN  Delivery      NaN   \n",
       "141             Delivery  NaN  Customer Service  Delivery    Price   \n",
       "155      Product Quality  NaN  Customer Service       NaN      NaN   \n",
       "312      Product Quality  NaN               NaN       NaN      NaN   \n",
       "\n",
       "            Aspect 4                        Output Labels  \n",
       "18               NaN                           [Delivery]  \n",
       "108              NaN                           [Delivery]  \n",
       "141              NaN  [Customer Service, Delivery, Price]  \n",
       "155  Product Quality  [Customer Service, Product Quality]  \n",
       "312  Product Quality                    [Product Quality]  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter for 'Mar-24' only\n",
    "df = df[df['Month of Response Date'] == \"Apr-24\"]\n",
    "df = df[df['Output Labels'] != \"[]\"]\n",
    "\n",
    "# Filter the DataFrame to exclude rows where 'Output Labels' is an empty list\n",
    "df = df[df['Output Labels'].map(lambda x: len(x) > 0)]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survey ID</th>\n",
       "      <th>Product Name</th>\n",
       "      <th>Print Customer Region</th>\n",
       "      <th>LTR</th>\n",
       "      <th>Source Type</th>\n",
       "      <th>Survey language</th>\n",
       "      <th>Review Source</th>\n",
       "      <th>Star Rating</th>\n",
       "      <th>Product Family</th>\n",
       "      <th>Supplies Family</th>\n",
       "      <th>...</th>\n",
       "      <th>predicted_aspect</th>\n",
       "      <th>max_predicted_probability</th>\n",
       "      <th>max_predicted_aspect</th>\n",
       "      <th>0</th>\n",
       "      <th>Aspect 1</th>\n",
       "      <th>Aspect 2</th>\n",
       "      <th>Aspect 3</th>\n",
       "      <th>Aspect 4</th>\n",
       "      <th>Output Labels</th>\n",
       "      <th>Label Vectors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>110020182</td>\n",
       "      <td>HP 63 Black Original Ink Cartridge</td>\n",
       "      <td>US</td>\n",
       "      <td>10</td>\n",
       "      <td>Web Reviews</td>\n",
       "      <td>English</td>\n",
       "      <td>Walmart</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Supplies - Ink</td>\n",
       "      <td>Dolmen Refresh</td>\n",
       "      <td>...</td>\n",
       "      <td>Delivery, 0</td>\n",
       "      <td>0.835220</td>\n",
       "      <td>Delivery</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Delivery</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[Delivery]</td>\n",
       "      <td>[1, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>123460320</td>\n",
       "      <td>HP 65XL Black Original Ink Cartridge</td>\n",
       "      <td>US</td>\n",
       "      <td>10</td>\n",
       "      <td>Web Reviews</td>\n",
       "      <td>English</td>\n",
       "      <td>Walmart</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Supplies - Ink</td>\n",
       "      <td>Dolmen Refresh</td>\n",
       "      <td>...</td>\n",
       "      <td>Delivery</td>\n",
       "      <td>0.790874</td>\n",
       "      <td>Delivery</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Delivery</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[Delivery]</td>\n",
       "      <td>[1, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>133472112</td>\n",
       "      <td>HP 64XL High Yield Tri-color Original Ink Cart...</td>\n",
       "      <td>US</td>\n",
       "      <td>10</td>\n",
       "      <td>Web Reviews</td>\n",
       "      <td>English</td>\n",
       "      <td>Walmart</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Supplies - Ink</td>\n",
       "      <td>Centaur</td>\n",
       "      <td>...</td>\n",
       "      <td>Delivery, Customer Service, Price</td>\n",
       "      <td>0.807059</td>\n",
       "      <td>Delivery</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Customer Service</td>\n",
       "      <td>Delivery</td>\n",
       "      <td>Price</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[Customer Service, Delivery, Price]</td>\n",
       "      <td>[1, 0, 1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>134626563</td>\n",
       "      <td>HP 65XL Black Original Ink Cartridge</td>\n",
       "      <td>US</td>\n",
       "      <td>10</td>\n",
       "      <td>Web Reviews</td>\n",
       "      <td>English</td>\n",
       "      <td>Walmart</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Supplies - Ink</td>\n",
       "      <td>Dolmen Refresh</td>\n",
       "      <td>...</td>\n",
       "      <td>Customer Service, Product Quality</td>\n",
       "      <td>0.761110</td>\n",
       "      <td>Product Quality</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Customer Service</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Product Quality</td>\n",
       "      <td>[Customer Service, Product Quality]</td>\n",
       "      <td>[0, 1, 0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312</th>\n",
       "      <td>172491173</td>\n",
       "      <td>HP 65XL Black Original Ink Cartridge</td>\n",
       "      <td>US</td>\n",
       "      <td>10</td>\n",
       "      <td>Web Reviews</td>\n",
       "      <td>English</td>\n",
       "      <td>Walmart</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Supplies - Ink</td>\n",
       "      <td>Dolmen Refresh</td>\n",
       "      <td>...</td>\n",
       "      <td>Product Quality</td>\n",
       "      <td>0.713346</td>\n",
       "      <td>Product Quality</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Product Quality</td>\n",
       "      <td>[Product Quality]</td>\n",
       "      <td>[0, 1, 0, 0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Survey ID                                       Product Name  \\\n",
       "18   110020182                 HP 63 Black Original Ink Cartridge   \n",
       "108  123460320               HP 65XL Black Original Ink Cartridge   \n",
       "141  133472112  HP 64XL High Yield Tri-color Original Ink Cart...   \n",
       "155  134626563               HP 65XL Black Original Ink Cartridge   \n",
       "312  172491173               HP 65XL Black Original Ink Cartridge   \n",
       "\n",
       "    Print Customer Region  LTR  Source Type Survey language Review Source  \\\n",
       "18                     US   10  Web Reviews         English       Walmart   \n",
       "108                    US   10  Web Reviews         English       Walmart   \n",
       "141                    US   10  Web Reviews         English       Walmart   \n",
       "155                    US   10  Web Reviews         English       Walmart   \n",
       "312                    US   10  Web Reviews         English       Walmart   \n",
       "\n",
       "     Star Rating  Product Family Supplies Family  ...  \\\n",
       "18           5.0  Supplies - Ink  Dolmen Refresh  ...   \n",
       "108          5.0  Supplies - Ink  Dolmen Refresh  ...   \n",
       "141          5.0  Supplies - Ink         Centaur  ...   \n",
       "155          5.0  Supplies - Ink  Dolmen Refresh  ...   \n",
       "312          5.0  Supplies - Ink  Dolmen Refresh  ...   \n",
       "\n",
       "                      predicted_aspect max_predicted_probability  \\\n",
       "18                         Delivery, 0                  0.835220   \n",
       "108                           Delivery                  0.790874   \n",
       "141  Delivery, Customer Service, Price                  0.807059   \n",
       "155  Customer Service, Product Quality                  0.761110   \n",
       "312                    Product Quality                  0.713346   \n",
       "\n",
       "    max_predicted_aspect    0          Aspect 1  Aspect 2 Aspect 3  \\\n",
       "18              Delivery  0.0               NaN  Delivery      NaN   \n",
       "108             Delivery  NaN               NaN  Delivery      NaN   \n",
       "141             Delivery  NaN  Customer Service  Delivery    Price   \n",
       "155      Product Quality  NaN  Customer Service       NaN      NaN   \n",
       "312      Product Quality  NaN               NaN       NaN      NaN   \n",
       "\n",
       "            Aspect 4                        Output Labels  Label Vectors  \n",
       "18               NaN                           [Delivery]   [1, 0, 0, 0]  \n",
       "108              NaN                           [Delivery]   [1, 0, 0, 0]  \n",
       "141              NaN  [Customer Service, Delivery, Price]   [1, 0, 1, 1]  \n",
       "155  Product Quality  [Customer Service, Product Quality]   [0, 1, 0, 1]  \n",
       "312  Product Quality                    [Product Quality]   [0, 1, 0, 0]  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert 'Output Labels' into binary vectors\n",
    "def labels_to_vector(row):\n",
    "    label_vector = [1 if label in row['Output Labels'] else 0 for label in output_labels]\n",
    "    return label_vector\n",
    "\n",
    "df['Label Vectors'] = df.apply(labels_to_vector, axis=1)\n",
    "\n",
    "# Prepare text data and labels for the model\n",
    "texts = df['Combined Text'].tolist()\n",
    "labels = df['Label Vectors'].tolist()\n",
    "\n",
    "# Tokenize the text data using DistilBertTokenizerFast\n",
    "tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')\n",
    "encodings = tokenizer(texts, truncation=True, padding=True, max_length=128)\n",
    "\n",
    "# Convert labels to torch tensors\n",
    "labels = torch.tensor(labels)\n",
    "\n",
    "# Create the dataset with the original DataFrame\n",
    "class MultilabelDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels, original_df):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "        self.original_df = original_df\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "# Create the dataset\n",
    "dataset = MultilabelDataset(encodings, labels, df)\n",
    "\n",
    "# Displaying the first few rows for validation\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Updated using Multilabel metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\angme\\AppData\\Local\\Temp\\ipykernel_2008\\1335597043.py:28: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item['labels'] = torch.tensor(self.labels[idx])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1 Classification Report (Training):\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "        Delivery       0.76      0.53      0.62       638\n",
      " Product Quality       0.70      0.52      0.60      1274\n",
      "           Price       0.91      0.73      0.81       791\n",
      "Customer Service       0.63      0.60      0.62      1640\n",
      "\n",
      "       micro avg       0.71      0.59      0.65      4343\n",
      "       macro avg       0.75      0.60      0.66      4343\n",
      "    weighted avg       0.72      0.59      0.65      4343\n",
      "     samples avg       0.63      0.62      0.60      4343\n",
      "\n",
      "\n",
      "Epoch 1 Classification Report (Validation):\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "        Delivery       0.84      0.65      0.73       158\n",
      " Product Quality       0.72      0.72      0.72       358\n",
      "           Price       0.78      1.00      0.88       185\n",
      "Customer Service       0.70      0.65      0.67       413\n",
      "\n",
      "       micro avg       0.74      0.73      0.73      1114\n",
      "       macro avg       0.76      0.75      0.75      1114\n",
      "    weighted avg       0.74      0.73      0.73      1114\n",
      "     samples avg       0.77      0.77      0.74      1114\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\angme\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\angme\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\angme\\AppData\\Local\\Temp\\ipykernel_2008\\1335597043.py:28: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item['labels'] = torch.tensor(self.labels[idx])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2 Classification Report (Training):\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "        Delivery       0.83      0.77      0.80       638\n",
      " Product Quality       0.77      0.76      0.76      1274\n",
      "           Price       0.95      0.95      0.95       791\n",
      "Customer Service       0.76      0.71      0.73      1640\n",
      "\n",
      "       micro avg       0.81      0.78      0.79      4343\n",
      "       macro avg       0.83      0.80      0.81      4343\n",
      "    weighted avg       0.81      0.78      0.79      4343\n",
      "     samples avg       0.83      0.82      0.80      4343\n",
      "\n",
      "\n",
      "Epoch 2 Classification Report (Validation):\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "        Delivery       0.87      0.63      0.73       158\n",
      " Product Quality       0.73      0.82      0.77       358\n",
      "           Price       0.89      0.97      0.93       185\n",
      "Customer Service       0.70      0.78      0.73       413\n",
      "\n",
      "       micro avg       0.76      0.80      0.78      1114\n",
      "       macro avg       0.80      0.80      0.79      1114\n",
      "    weighted avg       0.76      0.80      0.78      1114\n",
      "     samples avg       0.81      0.85      0.80      1114\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\angme\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\angme\\AppData\\Local\\Temp\\ipykernel_2008\\1335597043.py:28: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item['labels'] = torch.tensor(self.labels[idx])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 3 Classification Report (Training):\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "        Delivery       0.90      0.86      0.88       638\n",
      " Product Quality       0.84      0.83      0.84      1274\n",
      "           Price       0.97      0.96      0.97       791\n",
      "Customer Service       0.84      0.78      0.81      1640\n",
      "\n",
      "       micro avg       0.87      0.84      0.86      4343\n",
      "       macro avg       0.89      0.86      0.87      4343\n",
      "    weighted avg       0.87      0.84      0.86      4343\n",
      "     samples avg       0.90      0.88      0.87      4343\n",
      "\n",
      "\n",
      "Epoch 3 Classification Report (Validation):\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "        Delivery       0.84      0.65      0.74       158\n",
      " Product Quality       0.76      0.77      0.76       358\n",
      "           Price       0.98      0.85      0.91       185\n",
      "Customer Service       0.73      0.74      0.74       413\n",
      "\n",
      "       micro avg       0.79      0.75      0.77      1114\n",
      "       macro avg       0.83      0.75      0.79      1114\n",
      "    weighted avg       0.80      0.75      0.77      1114\n",
      "     samples avg       0.81      0.79      0.78      1114\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\angme\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\angme\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from transformers import DistilBertForSequenceClassification, AdamW\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import torch\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, hamming_loss, classification_report\n",
    "\n",
    "# Assuming 'dataset' is your prepared dataset\n",
    "\n",
    "# Split the dataset into training and validation sets (80% train, 20% validation)\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "# Create data loaders for training and validation\n",
    "batch_size = 16\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Load pre-trained DistilBERT model for multilabel classification (number of classes)\n",
    "output_labels = ['Delivery', 'Product Quality', 'Price', 'Customer Service']\n",
    "num_classes = len(output_labels)\n",
    "model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=num_classes)\n",
    "\n",
    "# Use GPU if available\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "model.to(device)\n",
    "\n",
    "# Optimizer\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
    "\n",
    "# Initialize lists to store metrics\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "metrics_list = []\n",
    "\n",
    "# Training loop\n",
    "epochs = 3\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    true_labels = []\n",
    "    predictions = []\n",
    "\n",
    "    for batch in train_loader:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].float().to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits  # Correctly access the logits\n",
    "\n",
    "        # Calculate loss\n",
    "        loss_fct = torch.nn.BCEWithLogitsLoss()\n",
    "        loss = loss_fct(logits, labels)\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # Store true labels and predictions for metrics\n",
    "        true_labels.append(labels.detach().cpu().numpy())\n",
    "        predictions.append((torch.sigmoid(logits) > 0.5).detach().cpu().numpy())\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Calculate average loss for this epoch\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    train_losses.append(avg_loss)\n",
    "\n",
    "    # Concatenate predictions and true labels for the training set\n",
    "    true_labels_concat = np.concatenate(true_labels)\n",
    "    predictions_concat = np.concatenate(predictions)\n",
    "\n",
    "    # Validation phase\n",
    "    model.eval()\n",
    "    val_total_loss = 0\n",
    "    val_true_labels = []\n",
    "    val_predictions = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].float().to(device)\n",
    "\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            logits = outputs.logits  # Correctly access the logits\n",
    "\n",
    "            val_loss = loss_fct(logits, labels)\n",
    "            val_total_loss += val_loss.item()\n",
    "\n",
    "            # Store true labels and predictions for metrics\n",
    "            val_true_labels.append(labels.detach().cpu().numpy())\n",
    "            val_predictions.append((torch.sigmoid(logits) > 0.5).detach().cpu().numpy())\n",
    "\n",
    "    # Calculate average loss for validation\n",
    "    avg_val_loss = val_total_loss / len(val_loader)\n",
    "    val_losses.append(avg_val_loss)\n",
    "\n",
    "    # Concatenate predictions and true labels for the validation set\n",
    "    val_true_labels_concat = np.concatenate(val_true_labels)\n",
    "    val_predictions_concat = np.concatenate(val_predictions)\n",
    "\n",
    "    # Compute performance metrics (macro and micro) for validation\n",
    "    f1_macro = f1_score(val_true_labels_concat, val_predictions_concat, average='macro')\n",
    "    f1_micro = f1_score(val_true_labels_concat, val_predictions_concat, average='micro')\n",
    "    precision_macro = precision_score(val_true_labels_concat, val_predictions_concat, average='macro')\n",
    "    precision_micro = precision_score(val_true_labels_concat, val_predictions_concat, average='micro')\n",
    "    recall_macro = recall_score(val_true_labels_concat, val_predictions_concat, average='macro')\n",
    "    recall_micro = recall_score(val_true_labels_concat, val_predictions_concat, average='micro')\n",
    "    hamming = hamming_loss(val_true_labels_concat, val_predictions_concat)\n",
    "\n",
    "    # Log metrics for this epoch\n",
    "    metrics_list.append({\n",
    "        'Epoch': epoch + 1,\n",
    "        'Train Loss': avg_loss,\n",
    "        'Validation Loss': avg_val_loss,\n",
    "        'F1 Score (Macro)': f1_macro,\n",
    "        'F1 Score (Micro)': f1_micro,\n",
    "        'Precision (Macro)': precision_macro,\n",
    "        'Precision (Micro)': precision_micro,\n",
    "        'Recall (Macro)': recall_macro,\n",
    "        'Recall (Micro)': recall_micro,\n",
    "        'Hamming Loss': hamming\n",
    "    })\n",
    "\n",
    "    # Generate classification reports for both training and validation\n",
    "    print(f\"\\nEpoch {epoch + 1} Classification Report (Training):\")\n",
    "    print(classification_report(true_labels_concat, predictions_concat, target_names=output_labels))\n",
    "\n",
    "    print(f\"\\nEpoch {epoch + 1} Classification Report (Validation):\")\n",
    "    print(classification_report(val_true_labels_concat, val_predictions_concat, target_names=output_labels))\n",
    "\n",
    "# Save training metrics to Excel\n",
    "metrics_df = pd.DataFrame(metrics_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch  Train Loss  Validation Loss  F1 Score (Macro)  F1 Score (Micro)  \\\n",
      "0      1    0.404305         0.353598          0.749849          0.733995   \n",
      "1      2    0.269680         0.298846          0.791624          0.779617   \n",
      "2      3    0.202863         0.320394          0.785958          0.772769   \n",
      "\n",
      "   Precision (Macro)  Precision (Micro)  Recall (Macro)  Recall (Micro)  \\\n",
      "0           0.758338           0.737319        0.754486        0.730700   \n",
      "1           0.795554           0.757191        0.800435        0.803411   \n",
      "2           0.828506           0.792453        0.751801        0.754039   \n",
      "\n",
      "   Hamming Loss  \n",
      "0      0.162804  \n",
      "1      0.139625  \n",
      "2      0.136313  \n"
     ]
    }
   ],
   "source": [
    "print(metrics_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizer saved to models/distilbert multilabels_v4df_mar-24\n",
      "Model with configuration saved to models/distilbert multilabels_v4df_mar-24\n"
     ]
    }
   ],
   "source": [
    "# Save the tokenizer\n",
    "tokenizer.save_pretrained('models/distilbert multilabels_v4df_mar-24')\n",
    "print(f'Tokenizer saved to models/distilbert multilabels_v4df_mar-24')\n",
    "\n",
    "# Save the entire model with configuration for future use\n",
    "model.save_pretrained('models/distilbert multilabels_v4df_mar-24')\n",
    "print(f'Model with configuration saved to models/distilbert multilabels_v4df_mar-24')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions saved to predicted_labels_v4df_apr-24.xlsx\n",
      "Filtered predictions saved to predicted_labels_v4df_apr-24.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification\n",
    "from torch.utils.data import DataLoader, Dataset  # Import Dataset\n",
    "\n",
    "# Function to prepare dataset from text\n",
    "def prepare_dataset(texts, tokenizer, max_length=512):\n",
    "    encodings = tokenizer(texts, truncation=True, padding=True, max_length=max_length, return_tensors=\"pt\")\n",
    "    return list(zip(encodings['input_ids'], encodings['attention_mask']))\n",
    "\n",
    "# Custom dataset for batching\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, encodings):\n",
    "        self.encodings = encodings\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.encodings)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            'input_ids': self.encodings[idx][0],\n",
    "            'attention_mask': self.encodings[idx][1]\n",
    "        }\n",
    "\n",
    "# Function to load model, predict, and update DataFrame\n",
    "def predict_and_update_dataframe(model_path, df, text_column='Combined Text', output_labels=None, batch_size=16):\n",
    "    # Load the tokenizer using relative paths\n",
    "    try:\n",
    "        tokenizer = DistilBertTokenizer.from_pretrained(model_path)\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading tokenizer: {e}\")\n",
    "        return\n",
    "\n",
    "    # Instantiate the model and load the weights\n",
    "    try:\n",
    "        model = DistilBertForSequenceClassification.from_pretrained(model_path, num_labels=len(output_labels))\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading model or weights: {e}\")\n",
    "        return\n",
    "\n",
    "    # Move model to device (use CPU if GPU is not available or out of memory)\n",
    "    # device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "    device = torch.device('cpu')\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    # Prepare the dataset from the DataFrame\n",
    "    dataset = df[text_column].tolist()  # Assuming 'Combined Text' contains the text data\n",
    "    encodings = prepare_dataset(dataset, tokenizer)\n",
    "\n",
    "    # Use DataLoader to load data in batches\n",
    "    data_loader = DataLoader(TextDataset(encodings), batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    predictions = []\n",
    "\n",
    "    # Perform inference in batches\n",
    "    with torch.no_grad():\n",
    "        for batch in data_loader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            logits = outputs.logits\n",
    "            preds = torch.sigmoid(logits).cpu().numpy()\n",
    "\n",
    "            # Convert predictions to label columns\n",
    "            for pred in preds:\n",
    "                labels = [output_labels[i] for i in range(len(output_labels)) if pred[i] >= 0.5]  # Threshold of 0.5\n",
    "                predictions.append(labels)\n",
    "\n",
    "    # Add predictions back to the DataFrame\n",
    "    df['Predicted Labels'] = predictions\n",
    "\n",
    "    # Save the updated DataFrame to an Excel file\n",
    "    df.to_excel('predicted_labels_v4df_apr-24.xlsx', index=False)\n",
    "    print('Predictions saved to predicted_labels_v4df_apr-24.xlsx')\n",
    "\n",
    "    # Save the filtered DataFrame to a CSV file\n",
    "    df.to_csv('predicted_labels_v4df_apr-24.csv', index=False)\n",
    "    print('Filtered predictions saved to predicted_labels_v4df_apr-24.csv')\n",
    "\n",
    "\n",
    "model_path = 'models/distilbert multilabels_v4df_mar-24'\n",
    "\n",
    "predict_and_update_dataframe(\n",
    "    model_path,\n",
    "    df,\n",
    "    output_labels=['Delivery', 'Product Quality', 'Price', 'Customer Service'],\n",
    "    batch_size=8  \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: 'The quality is good but the price is expensive.' => Sentiment Expressions: {'quality': 'Negative', 'price': 'Negative'}\n"
     ]
    }
   ],
   "source": [
    "import ollama\n",
    "\n",
    "def extract_sentiment_expression_llama(review, aspects, model_name='llama3.1'):\n",
    "    # Store the answers\n",
    "    answers = {}\n",
    "\n",
    "    # Iterate over the provided aspects to construct the prompt\n",
    "    for aspect in aspects:\n",
    "        prompt = f\"\"\"\n",
    "        Review: \"{review}\"\n",
    "        Aspect: \"{aspect}\"\n",
    "        What is the sentiment (positive, negative) for this aspect? Return the sentiment identified only. \n",
    "        \"\"\"\n",
    "\n",
    "        # Use the Ollama API to generate the sentiment expression\n",
    "        response = ollama.chat(\n",
    "            model=model_name, \n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "        )\n",
    "\n",
    "        # Extract the sentiment expression from the response\n",
    "        result_text = response['message']['content']\n",
    "        answers[aspect] = result_text.strip()\n",
    "\n",
    "    return answers\n",
    "\n",
    "# Example usage\n",
    "review = \"The quality is good but the price is expensive.\"\n",
    "aspects = [\"quality\", \"price\"]\n",
    "\n",
    "# Extract sentiment expressions for the review and specified aspects\n",
    "sentiment_expressions = extract_sentiment_expression_llama(review, aspects)\n",
    "print(f\"Review: '{review}' => Sentiment Expressions: {sentiment_expressions}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# need to change the code below to a df, so that we dont re-ingest as a new df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survey ID</th>\n",
       "      <th>Product Name</th>\n",
       "      <th>Print Customer Region</th>\n",
       "      <th>LTR</th>\n",
       "      <th>Source Type</th>\n",
       "      <th>Survey language</th>\n",
       "      <th>Review Source</th>\n",
       "      <th>Star Rating</th>\n",
       "      <th>Product Family</th>\n",
       "      <th>Supplies Family</th>\n",
       "      <th>...</th>\n",
       "      <th>max_predicted_probability</th>\n",
       "      <th>max_predicted_aspect</th>\n",
       "      <th>0</th>\n",
       "      <th>Aspect 1</th>\n",
       "      <th>Aspect 2</th>\n",
       "      <th>Aspect 3</th>\n",
       "      <th>Aspect 4</th>\n",
       "      <th>Output Labels</th>\n",
       "      <th>Label Vectors</th>\n",
       "      <th>Predicted Labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>101618952</td>\n",
       "      <td>HP 63 Black Original Ink Cartridge</td>\n",
       "      <td>US</td>\n",
       "      <td>10</td>\n",
       "      <td>Web Reviews</td>\n",
       "      <td>English</td>\n",
       "      <td>Walmart</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Supplies - Ink</td>\n",
       "      <td>Dolmen Refresh</td>\n",
       "      <td>...</td>\n",
       "      <td>0.954531</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Customer Service</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Price</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['Customer Service', 'Price']</td>\n",
       "      <td>[0, 0, 1, 1]</td>\n",
       "      <td>['Price', 'Customer Service']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>110317001</td>\n",
       "      <td>HP 63XL High Yield Black Original Ink Cartridge</td>\n",
       "      <td>US</td>\n",
       "      <td>10</td>\n",
       "      <td>Web Reviews</td>\n",
       "      <td>English</td>\n",
       "      <td>HP US</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Supplies - Ink</td>\n",
       "      <td>Dolmen Refresh</td>\n",
       "      <td>...</td>\n",
       "      <td>0.766199</td>\n",
       "      <td>Delivery</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Delivery</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['Delivery']</td>\n",
       "      <td>[1, 0, 0, 0]</td>\n",
       "      <td>['Delivery']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>113652950</td>\n",
       "      <td>HP 63 Black Original Ink Cartridge</td>\n",
       "      <td>US</td>\n",
       "      <td>10</td>\n",
       "      <td>Web Reviews</td>\n",
       "      <td>English</td>\n",
       "      <td>Walmart</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Supplies - Ink</td>\n",
       "      <td>Dolmen Refresh</td>\n",
       "      <td>...</td>\n",
       "      <td>0.809284</td>\n",
       "      <td>Price</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Price</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['Price']</td>\n",
       "      <td>[0, 0, 1, 0]</td>\n",
       "      <td>['Price']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>117483634</td>\n",
       "      <td>HP 65XL Tri-color Original Ink Cartridge</td>\n",
       "      <td>US</td>\n",
       "      <td>10</td>\n",
       "      <td>Web Reviews</td>\n",
       "      <td>English</td>\n",
       "      <td>Walmart</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Supplies - Ink</td>\n",
       "      <td>Dolmen Refresh</td>\n",
       "      <td>...</td>\n",
       "      <td>0.780703</td>\n",
       "      <td>Price</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Price</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['Price']</td>\n",
       "      <td>[0, 0, 1, 0]</td>\n",
       "      <td>['Price']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>118156397</td>\n",
       "      <td>HP 951XL 3-pack High Yield Cyan/Magenta/Yellow...</td>\n",
       "      <td>US</td>\n",
       "      <td>10</td>\n",
       "      <td>Web Reviews</td>\n",
       "      <td>English</td>\n",
       "      <td>Walmart</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Supplies - Ink</td>\n",
       "      <td>Nesta+</td>\n",
       "      <td>...</td>\n",
       "      <td>0.807181</td>\n",
       "      <td>Delivery</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Delivery</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['Delivery']</td>\n",
       "      <td>[1, 0, 0, 0]</td>\n",
       "      <td>['Delivery']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survey ID                                       Product Name  \\\n",
       "0  101618952                 HP 63 Black Original Ink Cartridge   \n",
       "1  110317001    HP 63XL High Yield Black Original Ink Cartridge   \n",
       "2  113652950                 HP 63 Black Original Ink Cartridge   \n",
       "3  117483634           HP 65XL Tri-color Original Ink Cartridge   \n",
       "4  118156397  HP 951XL 3-pack High Yield Cyan/Magenta/Yellow...   \n",
       "\n",
       "  Print Customer Region  LTR  Source Type Survey language Review Source  \\\n",
       "0                    US   10  Web Reviews         English       Walmart   \n",
       "1                    US   10  Web Reviews         English         HP US   \n",
       "2                    US   10  Web Reviews         English       Walmart   \n",
       "3                    US   10  Web Reviews         English       Walmart   \n",
       "4                    US   10  Web Reviews         English       Walmart   \n",
       "\n",
       "   Star Rating  Product Family Supplies Family  ... max_predicted_probability  \\\n",
       "0          5.0  Supplies - Ink  Dolmen Refresh  ...                  0.954531   \n",
       "1          5.0  Supplies - Ink  Dolmen Refresh  ...                  0.766199   \n",
       "2          5.0  Supplies - Ink  Dolmen Refresh  ...                  0.809284   \n",
       "3          5.0  Supplies - Ink  Dolmen Refresh  ...                  0.780703   \n",
       "4          5.0  Supplies - Ink          Nesta+  ...                  0.807181   \n",
       "\n",
       "  max_predicted_aspect   0          Aspect 1  Aspect 2 Aspect 3 Aspect 4  \\\n",
       "0                    0 NaN  Customer Service       NaN    Price      NaN   \n",
       "1             Delivery NaN               NaN  Delivery      NaN      NaN   \n",
       "2                Price NaN               NaN       NaN    Price      NaN   \n",
       "3                Price NaN               NaN       NaN    Price      NaN   \n",
       "4             Delivery NaN               NaN  Delivery      NaN      NaN   \n",
       "\n",
       "                   Output Labels Label Vectors               Predicted Labels  \n",
       "0  ['Customer Service', 'Price']  [0, 0, 1, 1]  ['Price', 'Customer Service']  \n",
       "1                   ['Delivery']  [1, 0, 0, 0]                   ['Delivery']  \n",
       "2                      ['Price']  [0, 0, 1, 0]                      ['Price']  \n",
       "3                      ['Price']  [0, 0, 1, 0]                      ['Price']  \n",
       "4                   ['Delivery']  [1, 0, 0, 0]                   ['Delivery']  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the Excel file\n",
    "file_path = 'predicted_labels_v4df_mar-24.xlsx'\n",
    "df = pd.read_excel(file_path)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "# Convert the 'Sentiment Expressions' column from string representation to dictionary\n",
    "df['Predicted Labels'] = df['Predicted Labels'].apply(ast.literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Survey ID                      int64\n",
      "Product Name                  object\n",
      "Print Customer Region         object\n",
      "LTR                            int64\n",
      "Source Type                   object\n",
      "Survey language               object\n",
      "Review Source                 object\n",
      "Star Rating                  float64\n",
      "Product Family                object\n",
      "Supplies Family               object\n",
      "Printer Family                object\n",
      "Model Name                    object\n",
      "Combined Text                 object\n",
      "Ink Supply Type               object\n",
      "token_count                    int64\n",
      "Month of Response Date        object\n",
      "predicted_level1              object\n",
      "predicted_probabilities       object\n",
      "predicted_aspect              object\n",
      "max_predicted_probability    float64\n",
      "max_predicted_aspect          object\n",
      "0                            float64\n",
      "Aspect 1                      object\n",
      "Aspect 2                      object\n",
      "Aspect 3                      object\n",
      "Aspect 4                      object\n",
      "Output Labels                 object\n",
      "Label Vectors                 object\n",
      "Predicted Labels              object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "df.head()\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to 'processed_sentiment_v4df_mar-24.xlsx'\n"
     ]
    }
   ],
   "source": [
    "# Applying the function to the DataFrame\n",
    "def process_dataframe(df):\n",
    "    # Since the 'Predicted Labels' are already lists, we rename this step\n",
    "    df['Aspect List'] = df['Predicted Labels']  # Copy over the already processed list\n",
    "\n",
    "    # Apply the sentiment extraction function to each row\n",
    "    df['Sentiment Expressions'] = df.apply(\n",
    "        lambda row: extract_sentiment_expression_llama(row['Combined Text'], row['Aspect List']), axis=1\n",
    "    )\n",
    "\n",
    "    return df\n",
    "\n",
    "# Apply to df\n",
    "df_new = process_dataframe(df)\n",
    "\n",
    "# Save the new DataFrame to an Excel file\n",
    "df_new.to_excel('processed_sentiment_data_v4df_mar-24.xlsx', index=False)\n",
    "\n",
    "print(\"Data saved to 'processed_sentiment_v4df_mar-24.xlsx'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "need to change the code so that it will auto-add the timestamp to the excel file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import ast\n",
    "\n",
    "# Example of how your data might look\n",
    "# df['Sentiment Expressions'] = [\"{'Delivery': 'Positive'}\", \"{'Price': 'Negative'}\"]\n",
    "\n",
    "# Convert the 'Sentiment Expressions' column to lists of dictionaries\n",
    "# df_new['Sentiment Expressions'] = df['Sentiment Expressions'].apply(\n",
    "#    lambda x: [ast.literal_eval(x)]\n",
    "# )\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "# print(df_new.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to process the sentiment expression and assign the label\n",
    "def process_sentiment_label(sentiment):\n",
    "    if any(keyword in sentiment for keyword in ['Negative', 'Concern', 'Not Satisfied', 'Mixed']):\n",
    "        return 'Negative'\n",
    "    elif any(keyword in sentiment for keyword in ['Positive', 'Satisfied']):\n",
    "        return 'Positive'\n",
    "    else:\n",
    "        return 'Neutral'\n",
    "\n",
    "# Function to expand rows for each aspect and sentiment\n",
    "def expand_rows_for_aspects(df):\n",
    "    expanded_rows = []\n",
    "\n",
    "    # Iterate through each row in the DataFrame\n",
    "    for index, row in df.iterrows():\n",
    "        # Get the sentiment dictionary from the row\n",
    "        sentiments = row['Sentiment Expressions']  # This is a dict e.g. {'Price': 'Positive', 'Customer Service': 'Negative'}\n",
    "\n",
    "        # Check if sentiments is a dictionary and not empty\n",
    "        if isinstance(sentiments, dict) and sentiments:\n",
    "            # Iterate over each aspect in the sentiment dictionary\n",
    "            for aspect, sentiment_expression in sentiments.items():\n",
    "                new_row = row.copy()  # Copy the current row\n",
    "                \n",
    "                # Create a new column for the current aspect\n",
    "                new_row['Aspect'] = aspect\n",
    "                \n",
    "                # Create a new column for the sentiment label based on the sentiment expression\n",
    "                new_row['Predicted Sentiment'] = process_sentiment_label(sentiment_expression)\n",
    "                \n",
    "                # Append the new row to the list\n",
    "                expanded_rows.append(new_row)\n",
    "        else:\n",
    "            # If there are no sentiments, append the original row without modifications\n",
    "            expanded_rows.append(row)\n",
    "\n",
    "    # Create a new DataFrame from the expanded rows\n",
    "    expanded_df = pd.DataFrame(expanded_rows)\n",
    "    \n",
    "    # Filter out rows where 'Predicted Sentiment' is blank or NaN\n",
    "    expanded_df = expanded_df[expanded_df['Predicted Sentiment'].notna() & (expanded_df['Predicted Sentiment'] != '')]\n",
    "    \n",
    "    return expanded_df\n",
    "\n",
    "\n",
    "# 'df_new' contains the columns 'Sentiment Expressions', which is a dictionary of aspects and sentiments\n",
    "df_expanded = expand_rows_for_aspects(df_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Survey ID                      int64\n",
      "Product Name                  object\n",
      "Print Customer Region         object\n",
      "LTR                            int64\n",
      "Source Type                   object\n",
      "Survey language               object\n",
      "Review Source                 object\n",
      "Star Rating                  float64\n",
      "Product Family                object\n",
      "Supplies Family               object\n",
      "Printer Family                object\n",
      "Model Name                    object\n",
      "Combined Text                 object\n",
      "Ink Supply Type               object\n",
      "token_count                    int64\n",
      "Month of Response Date        object\n",
      "predicted_level1              object\n",
      "predicted_probabilities       object\n",
      "predicted_aspect              object\n",
      "max_predicted_probability    float64\n",
      "max_predicted_aspect          object\n",
      "0                            float64\n",
      "Aspect 1                      object\n",
      "Aspect 2                      object\n",
      "Aspect 3                      object\n",
      "Aspect 4                      object\n",
      "Output Labels                 object\n",
      "Label Vectors                 object\n",
      "Predicted Labels              object\n",
      "Aspect List                   object\n",
      "Sentiment Expressions         object\n",
      "Aspect                        object\n",
      "Predicted Sentiment           object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df_expanded.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expanded data saved to 'expanded_sentiment_data_mar-24.xlsx'\n"
     ]
    }
   ],
   "source": [
    "def score_to_sentiment(row):\n",
    "    if not pd.isna(row['LTR']):\n",
    "        # use LTR (0-10)\n",
    "        if row['LTR'] <= 4:\n",
    "            return 'Negative'\n",
    "        else:\n",
    "            return 'Positive'\n",
    "    elif not pd.isna(row['Star Rating']):\n",
    "        # USe Star Rating (1-5)\n",
    "        if row['Star Rating'] <=2:\n",
    "            return 'Negative'\n",
    "        else:\n",
    "            return 'Positive'\n",
    "    else:\n",
    "        return 'Unknown'\n",
    "\n",
    "df_expanded['Actual Sentiment'] = df_expanded.apply(score_to_sentiment, axis=1)\n",
    "\n",
    "# Save the expanded DataFrame to an Excel file\n",
    "df_expanded.to_excel('expanded_sentiment_data_mar-24.xlsx', index=False)\n",
    "\n",
    "print(\"Expanded data saved to 'expanded_sentiment_data_mar-24.xlsx'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## this is for mar'24 \n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# 'df_expanded' is the DataFrame with 'Actual Sentiment' and 'Predicted Sentiment' columns\n",
    "def calculate_confusion_matrix(df):\n",
    "    # Check if the 'Actual Sentiment' and 'Predicted Sentiment' columns exist\n",
    "    if 'Actual Sentiment' not in df.columns or 'Predicted Sentiment' not in df.columns:\n",
    "        raise ValueError(\"Columns 'Actual Sentiment' and 'Predicted Sentiment' are required in the DataFrame\")\n",
    "\n",
    "    # Extract the actual and predicted sentiments\n",
    "    actual_sentiments = df['Actual Sentiment']\n",
    "    predicted_sentiments = df['Predicted Sentiment']\n",
    "\n",
    "    # Calculate the confusion matrix\n",
    "    cm = confusion_matrix(actual_sentiments, predicted_sentiments, labels=['Positive', 'Negative', 'Neutral'])\n",
    "\n",
    "    # Generate a classification report\n",
    "    report = classification_report(actual_sentiments, predicted_sentiments, target_names=['Positive', 'Negative', 'Neutral'])\n",
    "\n",
    "    return cm, report\n",
    "\n",
    "# Calculate the confusion matrix and classification report\n",
    "conf_matrix, class_report = calculate_confusion_matrix(df_expanded)\n",
    "\n",
    "# Display the results\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(class_report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[1387 1640   86]\n",
      " [   5 2038    8]\n",
      " [   0    0    0]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Positive       0.55      0.99      0.71      2051\n",
      "    Negative       0.00      0.00      0.00         0\n",
      "     Neutral       1.00      0.45      0.62      3113\n",
      "\n",
      "    accuracy                           0.66      5164\n",
      "   macro avg       0.52      0.48      0.44      5164\n",
      "weighted avg       0.82      0.66      0.65      5164\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\angme\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\angme\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\angme\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "## this is for apr'24 \n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# 'df_expanded' is the DataFrame with 'Actual Sentiment' and 'Predicted Sentiment' columns\n",
    "def calculate_confusion_matrix(df):\n",
    "    # Check if the 'Actual Sentiment' and 'Predicted Sentiment' columns exist\n",
    "    if 'Actual Sentiment' not in df.columns or 'Predicted Sentiment' not in df.columns:\n",
    "        raise ValueError(\"Columns 'Actual Sentiment' and 'Predicted Sentiment' are required in the DataFrame\")\n",
    "\n",
    "    # Extract the actual and predicted sentiments\n",
    "    actual_sentiments = df['Actual Sentiment']\n",
    "    predicted_sentiments = df['Predicted Sentiment']\n",
    "\n",
    "    # Calculate the confusion matrix\n",
    "    cm = confusion_matrix(actual_sentiments, predicted_sentiments, labels=['Positive', 'Negative', 'Neutral'])\n",
    "\n",
    "    # Generate a classification report\n",
    "    report = classification_report(actual_sentiments, predicted_sentiments, target_names=['Positive', 'Negative', 'Neutral'])\n",
    "\n",
    "    return cm, report\n",
    "\n",
    "# Calculate the confusion matrix and classification report\n",
    "conf_matrix, class_report = calculate_confusion_matrix(df_expanded)\n",
    "\n",
    "# Display the results\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(class_report)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
